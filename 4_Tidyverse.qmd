---
title: "Introducción al Tidyverse y exportación/importación de datos"
#author: " J. Miguel Salazar (msalazar@ecntrogeo.edu.mx), Ana J. Alegre (jalegre@centrogeo.edu.mx), Cristian Silva (csilva@centrogeo.edu.mx)"
format: live-html
webr:
  packages:
    - tidyverse
    - lubridate
    - janitor
  resources:
    - https://msalazarcgeo.github.io/Econometria_R_basicos/Datos/IDEFC_NM_abr22.csv

---
{{< include ./_extensions/r-wasm/live/_knitr.qmd >}}

## Introducción

El *data wrangling*, también conocido como *limpieza de datos* se refiere al proceso manual o automatizado mediante el cual los datos crudos son transformados en formatos más útiles para el análisis. Estos procesos incluyen la identificación de faltantes de infromación, la eliminación de datos irrelevantes, la combinación de múltiples fuentes de datos o la transformación de su estructura en una más apropiada (más conocida como *datos ordenados*).

Es posible usar el lenguaje *R* para leer, escribir y manipular datos que provienen de diferentes formatos, desde texto plano en *CSV* hasta formatos espaciales como *Shapefile*, *GeoPackage*, imágenes raster en *TIFF* entre otras. Una de las ventajas de usar *R* para el manejo de datos es la posibilidad de automatizar procesos previos al análisis de datos para ahorrar tiempo.

## Objetivo

El objetivo de esta sesión es realizar ejercicios con las principales funciones del paquete `tidyverse` para la manipulación de datos (*data wrangling*) y así filtrar, ordenar, agrupar y crear nuevas columnas. Para ello, usaremos el conjunto de datos de muestra llamado `iris` que se incluye en la instalación básica de *R*.

A continuación analizaremos datos reales que el gobierno de México publica para estudiar los homicidios reportados desde diciembre de 2018 hasta marzo de 2022, y compararemos aquellos que ocurren en la Ciudad de México (CDMX) con los que se registraron en los demás estados del país. Entonces, el segundo objetivo de esta sesión es importar y preparar los datos usando las funciones del *Tidyverse*.


## Repaso de Tidyverse

Siempre es recomendable limpiar el entorno antes de comenzar a trabajar. Ejecuta el siguiente *chunk* para limpiar todos los objetos del entorno:

```{webr }
#| label: Limpiar_entorno
#| eval: false
rm(list = ls(), quiet = TRUE)
```

:::{.callout-note}
Recuerda que para limpiar el entorno actual de R, también puedes utilizar el botón de la escoba en el panel *Environment*.
:::

Para esta sesión nos aseguraremos de tener instalados y actualizados todos los paquetes necesarios (descomenta la siguiente instrucción para instalar o actualizar los paquetes necesarios en caso de no tenerlos):

```{webr}
#| label: instalar_tidiverse
install.packages("tidyverse")
```

::: {.callout-note}
Recuerda que también puedes instalar o actualizar los paquetes necesarios para la sesión usando el panel "Packages" de RStudio.
:::

Carga el conjunto de datos de muestra `iris` en el entorno de R usando la función `data` y visualízalo en la siguiente línea:

```{webr}
#| label: load_iris
data("***") # Cargar el conjunto de datos "iris" en el entorno de R
*** # Visualizar los datos
```

Usa la función `library` para cargar el paquete `tidyverse` que usaremos para manipular los datos:

```{webr}
#| label: load_tidiverse
***(tidyverse)
```

### Exploración de datos

Visualiza rápidamente la estructura y contenidos de `iris`, usando la función `glimpse`:

```{webr}
#| label: glimp_iris
glimpse(***)
```

La función `glimpse` funciona como un equivalente en *Tidyverse* de la función básica `str`.

El operador conocido como *piline* (`%>%`) toma el resultado de la instrucción anterior y lo convierte en la entrada de la siguiente instrucción. Reescribe la instrucción del *chunk* anterior, usando una *pipe*:

```{webr}
#| label: glimpse_pipe
*** %>% 
  ***()
```

Encuentra los valores únicos de la variable `Species` del *dataframe* `iris` usando la función `distinct` y la sintaxis de *pipe*:

```{webr}
#| label: use_distinct
*** %>% 
  ***(Species) # Valores únicos de Species
```

### Seleccionar variables

Selecciona las variables `Sepal.Length` y `Species` del *dataframe* `iris` usando sus nombres con la función `select` y visualiza el resultado usando `glimpse`:

```{webr}
#| label: use_select
*** %>% 
  select(***, ***) %>% # Selecciona las variables deseadas
  glimpse() # Muestra la nueva estructura de datos
```

Selecciona las variables `Sepal.Length`, `Sepal.Width` y `Species`del *dataframe* `iris`y multiplícalas para crear una nueva variable llamada `Sepal.Multiply` usando la función `mutate` y visualiza el resultado usando `glimpse`:

```{webr}
#| label: use_mutate
*** %>% 
  ***(***, ***, ***) %>% # Seleccionar las variables
  mutate(Sepal.Multiply = *** * ***) %>% # A partir de las variables seleccionadas, crea una nueva
  ***() # Muestra la estructura de datos
```

### Filtrar los datos

Repite las operaciones anteriores pero conservando sólo las filas donde el valor de `Species` es *setosa*, usando la función `filter`:

```{webr}
#| label: use_filter
*** %>% 
  ***(***, ***, ***) %>% 
  ***(*** = *** * ***) %>% 
  filter(Species == "***") # Filtra las filas donde Species sea igual a "setosa"
```

Repite las operaciones anteriores, pero conservando sólo las filas donde los valores de `Species` son *setosa* y *versicolor* y el valores de `Sepal.Length` es mayor que 4.5, usando la función `filter`:

```{webr}
#| label: use_filter_bool
*** %>% 
  ***(***, ***, ***) %>% 
  ***(*** = *** * ***) %>%
  filter(Species %in% c("***", "***") & Sepal.Length > ***)  # Filtra las filas con varias condiciones
```

### Ordenar los datos

Repite las operaciones anteriores y ordena los datos por `Sepal.Length` en orden ascendente usando la función `arrange`:

```{webr}
#| label: use_arrange_sort
*** %>% 
  ***(***, ***, ***) %>% 
  ***(*** = *** * ***) %>% 
  ***(*** %in% c("***", "***") & *** > ***) %>% 
  arrange(***) # Ordena las filas
```

Repite las operaciones anteriores ordenando los datos ahora por `Sepal.Length` en orden descendente usando `desc` y luego por `Sepal.Multiply` orden ascendente, usando la función `arrange`:

```{webr}
#| label: use_arrenge_desc
*** %>% 
  ***(***, ***, ***) %>% 
  ***(*** = *** * ***) %>% 
  ***(*** %in% c("***", "***") & *** > ***) %>% 
  arrange(desc(***), ***) # Ordena las filas por Sepal.Length descendiente y Sepal.Multiply ascendente
```

### Agrupar y resumir los datos

Cuenta el número de observaciones (filas) por cada valor único de la variable `Species` del *dataframe* `iris`, usando la función `count`:

```{webr}
#| label: contar 
*** %>% 
  count(***)
```

Para crear grupos categóricos usando variables se usa la función `group_by`. Agrupa los datos del *dataframe* `iris` usando el campo categórico `Species`:

```{webr }
#| label: use_grupby
*** %>% 
  group_by(***) # Agrupar datos por valor
```

Este conjunto de datos no tiene cambios visibles, pero se crearon grupos para calcular en ellos estadísticos como estos:

-   Número de observaciones (n, cuenta)
-   Sumatoria
-   Media
-   Mínimo
-   Máximo
-   Mediana
-   Desviación estándar

Crea nuevas columnas con los estadísticos de la variable `Petal.Length` agrupados por cada valor único de la variable `Species`, usando la función `summarize` después de la función `group_by` y definiendo cada uno de los estadísticos con las funciones `n` (conteo), `sum` (sumatoria), `min` (mínimo), `max` (máximo), `mean` (promedio), `median` (mediana) y `sd` (desviación estándar):

```{webr}
#| label: Sumerize
#| caption: Conmpendio
#| exercise: ex_summerize
*** %>% 
  group_by(***) %>% 
  summarize(Petal.Cuenta = n(),
            Petal.Sumatoria = sum(Petal.Length),
            Petal.Minimo = min(Petal.Length),
            Petal.Maximo = max(Petal.Length),
            Petal.Media = mean(Petal.Length),
            Petal.Mediana = median(Petal.Length),
            Petal.DesvEst = sd(Petal.Length))
```

::: {.solution exercise="ex_summerize"}
#### Solution

```{webr}
#| exercise: ex_summerize
#| solution: true
iris %>% 
  group_by(Species) %>% 
  summarize(Petal.Cuenta = n(),
            Petal.Sumatoria = sum(Petal.Length),
            Petal.Minimo = min(Petal.Length),
            Petal.Maximo = max(Petal.Length),
            Petal.Media = mean(Petal.Length),
            Petal.Mediana = median(Petal.Length),
            Petal.DesvEst = sd(Petal.Length))

```
:::


Después de resumir los datos se conservan *agrupados*, es por eso que regularmente es necesario eliminar la agrupación y mantener el conjunto de datos transformado antes de realizar cualquier otra operación, para esto se usa la función `ungroup`. Repite la agrupación y sumarización del *chunk* anterior y desagrupa usando la función `ungroup`:

```{webr }
#| label: resumir y desagrupar datos

*** %>% 
  ***(***) %>% 
  ***(Petal.Cuenta = ***(),
      Petal.Sumatoria = ***(***),
      Petal.Minimo = ***(***),
      Petal.Maximo = ***(***),
      Petal.Media = ***(***),
      Petal.Mediana = ***(***),
      Petal.DesvEst = ***(***)) %>% 
  ungroup()
```

### Caso práctico: Homicidios a nivel nacional

### Importar los datos

En esta sesión, usaremos los datos abiertos de incidencia delictiva que publica el *Secretariado Ejecutivo del Sistema Nacional de seguridad Pública (SESNSP)* que están disponibles en el portal de datos abiertos del Gobierno de México en <https://www.datos.gob.mx/busca/dataset/incidencia-delictiva-del-fuero-comun>. Estos datos contienen la información de delitos cometidos a nivel estatal y serán usados en el taller más adelante para comparar los niveles de homicidios que ocurrieron en la CDMX y en los demás estados del país.

Carga el paquete `lubridate` para manejar más fácilmente los tipos de datos fecha-hora del conjunto de datos, y también carga el paquete `janitor` para realizar algunos procesos de limpieza a los datos:

```{webr }
#| label: Librerías para manipulación y limpieza de datos
***(lubridate)
***(janitor)

```


Este es un conjunto de datos que originalmente viene en un formato de texto plano separado por comas (*CSV*). Observa y ejecuta el siguiente *chunk* para leer el archivo de datos usando la función de `read_csv` de `tidyverse` (no la instrucción `read.csv` de *R* base) y asigna los datos a una nueva variable que se llame `delitos`:

```{webr}
#| label: importar_datos
#fuente_de_datos <- "Datos/IDEFC_NM.csv" # Desde el archivo descargado en la carpeta Datos

fuente_de_datos <- "https://msalazarcgeo.github.io/Econometria_R_basicos/Datos/IDEFC_NM_abr22.csv" # Directo desde el sitio del repositorio
#download.file(fuente_de_datos, "IDEFC_NM.csv")
delitos <- 
 read_csv(file = fuente_de_datos,
           locale = locale(encoding = "WINDOWS-1252")) %>%  
  clean_names() %>% 
  glimpse() 
```

En el *chunk* anterior, puedes observar lo siguiente:

-   En la instrucción `read_csv` se incluye un parámetro `locale = locale(encoding = "WINDOWS-1252")`. Esto se usa por que los datos originales se crearon en Windows, y aunque se puede omitir, no especificar esto puede provocar que aparezcan caracteres incorrectos en los datos al importarlos en otros sistemas operativos como macOS o Linux que usan el tipo de codificación *UTF-8*. \# La función `clean_names` del paquete `janitor` convierte los nombres de las columnas a minúsculas, reemplaza los espacios con '\_' y reemplaza caracteres especiales y con acentos para evitar problemas al escribir códigos.

### Preparar los datos

Los datos agrupan los totales de delitos en 12 columnas para cada mes, pero esta estructura no es útil para filtrar los datos por rangos de fecha. Para poder filtrar los datos por fecha, será necesario tener una columna `mes` de tipo de datos *fecha* en una forma de tabla *larga*. El siguiente bloque ejecutará en cadena las siguientes operaciones:

1.  Transformar la estructura a una forma *larga*, guardando los nombres de cada columna de mes en una nueva columna llamada `mes_nombre` y sus valores en una nueva columna llamada `total` usando la función `pivot_longer`.
2.  Obtener el número del mes a partir de `mes_nombre` usando la función `case_when` para guardar el valor numérico correspondiente en una nueva columna llamada `mes_numero`.
3.  Construir el mes en formato *fecha* usando las columnas `ano`, `mes_numero` y el número 1 para asumir el primer día del mes, para lo que se usa la función `make_date` para crear una nueva columna llamada `mes`.
4.  Finalmente quitar las columnas `mes_nombre`, `mes_numero`, `ano` que ya son innecesarias usando la función `select` y el signo `-` para excluirlas del *tibble* resultante.

Observa cómo se construyó ésta secuencia usando las *pipeline* en el siguiente *chunk*, ejecútalo y observa el resultado:

```{webr }
#| label: Limpiar_transformar
delitos <-
  delitos %>% 
  pivot_longer(cols = 8:19,
               names_to = "mes_nombre",
               values_to = "total") %>% 
  mutate(mes_numero = case_when(mes_nombre == "enero" ~ 1,
                                mes_nombre == "febrero" ~ 2,
                                mes_nombre == "marzo" ~ 3,
                                mes_nombre == "abril" ~ 4,
                                mes_nombre == "mayo" ~ 5,
                                mes_nombre == "junio" ~ 6,
                                mes_nombre == "julio" ~ 7,
                                mes_nombre == "agosto" ~ 8,
                                mes_nombre == "septiembre" ~ 9,
                                mes_nombre == "octubre" ~ 10,
                                mes_nombre == "noviembre" ~ 11,
                                mes_nombre == "diciembre" ~ 12)) %>%
  mutate(mes = make_date(ano, mes_numero, 1)) %>% 
  select(-ano, -mes_nombre, -mes_numero) %>% 
  glimpse()
```

Para conocer la clasificación de los delitos a partir de los datos, crea una lista de los tipos de delitos a partir de los datos. Para ello construye con *pipeline* la siguiente secuencia de operaciones y guarda el resultado en una nueva variable llamada `lista_delitos`:

1.  Toma como base los datos del *tibble* `delitos`.
2.  Usa la función `distinct` para obtener las categorías únicas de las columnas `bien_juridico_afectado`, `tipo_de_delito`, `subtipo_de_delito` y `modalidad`.
3.  Ordena los datos usando los campos `bien_juridico_afectado`, `tipo_de_delito`, `subtipo_de_delito` y `modalidad` en ése orden con la función `arrange`.

En la línea siguiente visualiza el contenido del *tibble* `lista_delitos` resultante.

```{webr}
#| label: Lista_delitos
#| exercise: ex_list_delitos
lista_delitos <-
  *** %>% 
  distinct(***, ***, ***, ****) %>% # Mantiene los valores únicos de las columnas
  arrange(***, ***, ***, ***) # Ordena los valores de forma ascendente

# Muestra la lista de delitos:
***
```
::: {.solution exercise="ex_list_delitos"}
#### Solución
```{webr}
#| exercise: ex_list_delitos
#| solution: true
lista_delitos <-
  delitos %>% 
  distinct(bien_juridico_afectado, tipo_de_delito, subtipo_de_delito,modalidad) %>% 
  arrange(bien_juridico_afectado, tipo_de_delito, subtipo_de_delito ,modalidad) # Ordena los valores de forma ascendente

# Muestra la lista de delitos:
glimpse(lista_delitos)
```
:::

Obtén los datos de homicidios que ocurrieron **desde diciembre 2018 hasta junio 2020**. Primero, es necesario definir las fechas de inicio y fin del periodo que necesitamos. Usa la función `make_date` del paquete `lubridate` para construir las variables `mes_inicial` y `mes_final` con tipo de datos de fecha:

```{webr Definir el periodo requerido}
mes_inicial <- make_date(2018, 12, 1) # 2018-12-01
mes_final <- ***(***, ***, ***) # 2020-06-30
```

Después, usa las *pipeline* para arreglar los datos y guardar en una nueva variable llamada `homicidios` el resultado de la siguiente secuencia de operaciones:

1.  Toma el *tibble* `delitos` como base.
2.  Filtra los datos usando las condiciones `tipo_de_delito == "Homicidio"` y `mes %>% between(mes_inicial, mes_final)` para mantener sólo los datos de homicidios y sus subcategorías en el periodo indicado usando la función `filter`.
3.  Visualiza la estructura del *tibble* resultante usando la función `glimpse`.

```{webr}
#| label: Filtrar datos nacionales
#| exercise: ex_filtrar_datos
homicidios <-
  *** %>% # Datos de delitos
  ***(*** == "***" & *** %>% between(***, ***)) %>% # Filtros aplicados
  ***() # Visualizar la estructura del tibble resultante
```

::: {.solution exercise="ex_filtrar_datos"}
#### Solution
```{webr}
#| exercise: ex_filtrar_datos
#| solution: true

homicidios <- delitos %>% # Datos de delitos
  filter(tipo_de_delito == "Homicidio" & mes %>% between(mes_inicial,mes_final )) #%>% # Filtros aplicados
glimpse(homicidios) # Visualizar la 
```
:::

Para conocer la evolución de los homicidios en cada estado y en el tiempo, agrupa y sumariza los totales de homicidios por entidad y mes. Asigna a una variable llamada `homicidios_por_estado` el resultado de las siguientes operaciones:

1.  Toma el *tibble* homicidios como base.
2.  Agrupa los datos por cada `clave_ent`, `entidad`, y `mes`.
3.  Obtén la suma del total de homicidios (usando el parámetro `na.rm = TRUE` para omitir los registros vacíos o `NA`) y guárdala en una nueva columna llamada `homicidios_totales`.
4.  Desagrupa los datos.
5.  Visualiza la estructura resultante.

```{webr}
#| label: Agrupar y sumarizar homicidios
#| exercise: ex_agrupar_sum
homicidios_por_estado <-
  *** %>% # Datos de homicidios
  ***(***, ***, ***) %>% # Agrupar por clave_ent, entidad, y mes
  ***(homicidios_totales = sum(***, na.rm = TRUE)) %>% # Sumarizar el total de delitos quitando vacíos
  ***() %>% # Desagrupar
  ***() # Visualizar la estructura del tibble resultante
```

::: {.solution exercise="ex_agrupar_sum"}
#### Solution
```{webr}
#| exercise: ex_agrupar_sum
#| solution: true

homicidios_por_estado <-
  homicidios %>% # Datos de homicidios
  group_by(clave_ent, entidad,  mes) %>% # Agrupar por clave_ent, entidad, y mes
  summarize(homicidios_totales = sum(total, na.rm = TRUE)) %>% # Sumarizar el total de delitos quitando vacíos
  ungroup() %>% # Desagrupar
  glimpse() # Visualizar la estructura del tibble resultante

```
:::






### Exportar los datos

Finalmente, guarda una copia de `homicidios_por_estado` usando *pipeline* y las funciones `write_csv` o `write_excel_csv` para guardar los datos en formato *CSV* en el archivo `homicidios_por_estado.csv` en la carpeta `Datos` (se usarán más adelante en el taller):

```{webr Guardar datos nacionales en CSV}
# Descomenta la versión que quieras usar de las siguientes instrucciones:

# La instrucción write_csv respeta la codificación de Windows, macOS o Linux: 
# homicidios_por_estado %>% 
#   write_csv("***")

# Usa esta función si los datos se van a abrir en Excel:
homicidios_por_estado %>% 
  write_excel_csv("***")
```


## Visualización de datos

En **R** para generar gráficos qe nos ayunden a entender las problemáticas de forma gráfica la biblioteca comunmente más utilizada es `ggplot2`. 


```{webr}
library(ggplot2)
```

Para empezar a construir algunas visualizaciones a partir de datos, usaremos los datos de muestra llamados `mtcars` que se incluyen con la distribución base de *R*. Para saber más acerca de la fuente y del contenido de este conjunto de datos, usa la función `help` para consultar la documentación de `mtcars` en el panel *Help* de *RStudio*:

```{webr}
#| label: ayuda_datos
***(mtcars)
```

Carga en el entorno los datos de muestra incluidos en *R* llamados `mtcars` usando la función `data` y previsualiza su contenido:

```{webr }
#| label: carga_datos
***("mtcars")

*** # Previsualiza el contenido de mtcars la tabla de datos
```

### Gráficas de dispersión de puntos (*scatterplot*)

Consulta y lee la documentación de la función `ggplot` usando `help`:

```{webr}
#| label: ayuda_ggplot
***(***) # Consulta la ayuda de ggplot en el panel help
```

Ejecuta el siguiente *chunk* para construir una gráfica de dispersión de puntos a partir de los datos de `mtcars` para visualizar la correlación entre las millas por galón (`mpg`) en el eje *x* y el peso (`wt`) en el eje *y*, usando la función `ggplot` y sumando una capa de puntos con la función `geom_point`:

```{webr}
#| label: Gráfica_dispersión_básica
ggplot(data = mtcars, mapping = aes(x = mpg, y = wt)) +
  geom_point()
```

De la gráfica anterior se puede observar una correlación negativa entre el peso y las millas por galón, es decir, **los vehículos con mayor peso tienen un rendimiento menor en millas por galón**.

Repite el ejercicio anterior, pero ahora agrega una línea de tendencia sumando una capa `geom_smooth` a la gráfica anterior:

```{webr }
#| label: Grafica_dispersion_tendencia
***(data = ***, mapping = aes(x = ***, y = ***)) +
  ***() +
  geom_smooth()
```

Repite el ejercicio anterior, pero ahora agrega una línea de tendencia lineal sumando una capa `geom_smooth` a la gráfica anterior usando los parámetros `color = red` para pintar la línea de tendencia en rojo, `method = lm` para usar el modelo lineal y `se = FALSE` para ocultar el sombreado de error estándar. Guarda la gráfica en una nueva variable llamada `gráfica_mpg_vs_wt` y llámala para visualizarla:

```{webr }
#| label: Grafica_dispersion_tendencia_lineal
grafica_mpg_vs_wt <-
  ***(data = ***, mapping = aes(x = ***, y = ***)) +
  ***() +
  geom_smooth(color = ***,
              method = ***,
              se = ***)

*** # Visualizar la gráfica
```

Agrega un título, un subtítulo y etiquetas los ejes *x* y *y* a la gráfica `grafica_mpg_vs_wt` sumándole la función `labs` con los siguientes parámetros:

-   `title = "Correlación entre peso y millas por galón"` para incluir el título de la gráfica.
-   `subtitle = "Conjunto de datos mtcars"` para incluir un subtítulo.
-   `x = "Millas por galón"` para incluir la etiqueta del eje *x*.
-   `y = "Peso (1000 lb)"` para incluir la etiqueta del eje *y*.
-   `caption = "Fuente: 1974 Motor Trend US magazine"` para agregar una nota al pie.

```{webr}
#| label: Grafica_etiquetas
grafica_mpg_vs_wt <-
  *** +
  labs(title = ***,
       subtitle = ***,
       x = ***,
       y = ***,
       caption = ***)

*** # Visualiza la gráfica actualizada
```

Agrega un formato preestablecido (*tema*) a la gráfica usando `grafica_mpg_vs_wt` sumándole la función `theme_classic`:

```{webr}
#| label: Grafica_dispersión_tema
grafica_mpg_vs_wt <- 
  *** +
  theme_classic()

*** # Visualiza la gráfica actualizada
```

Repite desde el principio el ejercicio anterior incluyendo todas las capas pero ahora categoriza coloreando de diferentes tonos cada uno de los puntos según el número de cilindros del auto (`cyl`) usando la estética `aes(x = mpg, y = wt, color = as.factor(cyl))` en la función `ggplot` del principio:

```{webr}
#| label: Gráfica_dispersión_categorías
***(***, aes(x = ***, y = ***, color = as.factor(***))) + # Es necesario convertir cyl a factor ya que viene como numérico
  ***) +
  ***(*** = ***,
      *** = ***,
      *** = ***) +
  ***(title = ***,
      subtitle = ***,
      x = ***,
      y = ***,
      caption = ***,
      color = ***) + # Agrega el texto a la etiqueta "color" para la leyenda
  theme_classic()
```

A veces es más conveniente usar diferentes gráficas por separado para cada categoría, a estas gráficas separadas pero vinculadas por la escala y los datos se les conoce como *facetas*. Repite el ejercicio anterior pero sin incluir `color = cyl"` en la estética `aes` ni `color = "Cilindros"` en las etiquetas `labs`, para comparar las correlaciones de millas por galón (`mpg`) y peso (`wt`) pero ahora usa la función `facet_wrap(~cyl)` para crear facetas por cilindraje:

```{webr}
#| label: Grafica_dispersion_facetas
***(***, aes(x = ***, y = ***)) + # Ya no es necesario incluir "cyl" como color
  ***() +
  ***(color = ***,
      method = ***,
      se = ***) +
  ***(title = ***,
      subtitle = ***,
      x = ***,
      y = ***,
      caption = ***) +
  facet_wrap(~cyl) +
  theme_classic()
```

### Histogramas

El paquete `ggplot2` tiene otras geometrías diferentes que puede utilizar para visualizar diferentes tipos de datos. Uno de los más comunes es el **histograma**.

Ejecuta el siguiente *chunk* para crear un histograma a partir de la potencia de los autos (`hp`) en los datos de `mtcars` definiendo la estética `aes(x = hp)` y usando la geometría `geom_histogram`:

```{webr Histograma básico}
ggplot(mtcars, aes(x = hp)) +
  geom_histogram()
```

Repite el ejercicio anterior separando por color de las barras los cilindros, usando la estética `aes(x = hp, fill = cyl)`:

```{webr Histograma con categorías}
***(***, aes(x = ***, fill = as.factor(***))) + # Recuerda convertir cyl a variable categórica (factor) con as.factor
  ***()
```

Ordena las barras poniendolas lado a lado por categoría usando el parámetro `position = "stack"` en la función `geom_histogram`:

```{webr Histograma con categorías lado a lado}
***(***, aes(x = ***, fill = as.factor(***))) + # Recuerda convertir cyl a variable categórica (factor) con as.factor
  ***(position = ***)
```

**Ejercicio extra:** Repite el gráfico anterior y agrega las etiquetas necesarias para documentar el gráfico y cambia el formato usando el tema `theme_dark`.

```{webr}
#| label: Ejercicio_histograma
# Escribe aquí el código
```

### Diagramas de cajas y bigotes (*box plot*)

Permiten entender la distribución de los valores de una variable de manera visual. Para este ejercicio usaremos los datos de ejemplo de medidas de flores `iris` incluidas en *R*. Para saber más acerca de la fuente y del contenido de este conjunto de datos, consulta y lee la documentación de `mtcars` en el panel *Help* de *RStudio*, usando la función `help` :

```{webr }
#| label: ayuda_iris
help(***)
```

Carga en el entorno los datos de muestra incluidos en *R* llamados `mtcars` usando la función `data` y previsualiza su contenido:

```{webr}
#| label: Cargar datos iris
***("iris")

*** # Previsualiza el contenido de iris la tabla de datos
```

Ejecuta el siguiente *chunk* para verificar la distribución de las medidas de longitud del sépalo (`Sepal.Length`) para cada una de las especies (`Species`) usando la geometría `geom_boxplot`:

```{webr}
#| label: Diagrama_caja_basico
ggplot(iris, aes(x = Species, y = Sepal.Length)) +
  geom_boxplot()
```

Repite el gráfico anterior y agrega las etiquetas necesarias para documentar el gráfico y cambia el formato usando el tema `theme_linedraw`:

```{webr}
#| label: Ejercicio_diagrama_caja
#| exercise: ex_box_plot
# Escribe aquí el código
```

```{webr}
#| exercise: ex_box_plot
#| solution: true
ggplot(iris, aes(x = Species, y = Sepal.Length)) +
  geom_boxplot()+
labs(
  title="Especies de flores",
  x="Especies",
  y="Sépalo"
)+
theme_linedraw()
```




### Caso práctico: Homicidios dolosos a nivel nacional

Lee el conjunto de datos que se preparó anteriormente con los homicidios por estado y por mes (`homicidios_por_estado.csv`) usando la función `read_csv` y guárdalos en la variable `homicidios_por_estado`:

```{webr Leer datos de homicidio por estado}
homicidios_por_estado <-
  ***(***) %>% 
  ***()
```

### Evolución de los homicidios a nivel nacional

Para visualizar la tendencia nacional de homicidios, es necesario preparar una serie de datos por mes con el total sumarizado de homicidios. Construye la serie de datos necesaria haciendo la siguiente secuencia de operaciones usando *pipes*:

1.  Toma como base los datos de `homicidios_por_estado`.
2.  Agrupa usando la variable `mes` usando la función `group_by`.
3.  Sumariza la variable `homicidios_totales` y guarda el resultado en una nueva variable llamada `homicidios_total` usando las funciones `summarize` y `sum` (omite los valores vacíos si existen usando el parámetro `na.rm = TRUE`).
4.  Desagrupa los datos usando la función `ungroup`.

Visualiza el contenido de la serie `homicidios_por_mes` para comprobar que la transformación está correcta.

```{webr Preparar serie de datos}

homicidios_por_mes <-
  *** %>% 
  group_by(***) %>% 
  ***(homicidios_total = sum(***, na.rm = ***)) %>% 
  ***()

# Visualiza la serie:
***
```

Construye una gráfica de línea para visualizar la tendencia mensual de los homicidios siguiendo la siguiente secuencia de operaciones:

1.  Toma como base los datos de `homicidios_por_mes`.
2.  Define los campos que se usarán en los ejes *x* y *y* en la estética que usará la gráfica con `aes(x = mes, y = homicidios_totales)` dentro de la función `ggplot`.
3.  Agrega una geometría de líneas sumando la función `geom_line`.
4.  Agrega un modelo de regresión con la función `geom_smooth` (por esta ocasión usaremos los parámetros por defecto).
5.  Incluye el título, subtítulo y las etiquetas de los ejes usando la función `labs`.

```{webr Gráfica de líneas con datos nacionales}
homicidios_por_mes %>% 
  ***(aes(x = ***, y = ***)) + # Crea una gráfica vacía con el mes en x y los homicidios en y
  ***() + # Agrega una línea de tendencia
  ***() + # Agregar una línea de regresión
  ***(title = ***,
      subtitle = ***,
      x = ***,
      y = ***,
      caption = ***) # Agrega los títulos y etiquetas de ejes
```

Repite los pasos anteriores para crear una línea de tendencia usando ahora sólo los datos de la CDMX para compararlos con la tendencia nacional. Para ello, sigue la siguiente secuencia de operaciones:

1.  Toma como base los datos de `homicidios_por_estado`.
2.  Filtra los datos donde `entidad == "Ciudad de México` usando la función `filter`.
3.  Define los campos que se usarán en los ejes *x* y *y* en la estética que usará la gráfica con `aes(x = mes, y = homicidios_totales)` dentro de la función `ggplot`.
4.  Agrega una geometría de líneas sumando la función `geom_line`.
5.  Agrega un modelo de regresión con la función `geom_smooth` (por esta ocasión usaremos los parámetros por defecto).
6.  Incluye el título, subtítulo y las etiquetas de los ejes usando la función `labs`.

```{webr Gráfica de líneas con datos de CDMX}
homicidios_por_estado %>%
  ***(entidad == ***) %>% # Filtra los datos para CDMX
  ***(aes(x = ***, y = ***)) + # Crea una gráfica vacía con el mes en x y los homicidios en y
  ***() + # Agrega una línea de tendencia
  ***() + # Agregar una línea de regresión
  ***(title = ***,
      subtitle = ***,
      x = ***,
      y = ***,
      caption = ***) # Agregar títulos y etiquetas de ejes
```

Como puede observarse en ambas gráficas, durante el periodo de diciembre 2018 a junio 2021, la tendencia de homicidios a nivel nacional ha ido en descenso durante los meses recientes. Igualmente en la CDMX, han descendido durante el periodo con algunos incrementos durante los primeros meses del año


## Referencias

-   Wickham, H., & Grolemund, G. (2017). *R for data science: Import, tidy, transform, visualize and model data.* [https://r4ds.had.co.nz](https://r4ds.had.co.nz){target="_blank"}. O'Reilly.
-   Lovelace, R., Nowosad, J., & Muenchow, J. (2019), *Geocomputation with R.* [https://geocompr.robinlovelace.net](https://geocompr.robinlovelace.net){target="_blank"}. CRC Press.
-   Tennekes, M., Nowosad, J. (2021). *Elegant and informative maps with tmap. Desde [https://r-tmap.github.io/tmap-book/](https://r-tmap.github.io/tmap-book/){target="_blank"}
-   Engel, C. (2019). *Using Spatial Data with R.* cengel.github.io. Desde [https://cengel.github.io/R-spatial/](https://cengel.github.io/R-spatial){target="_blank"}.
